# Stage 0.5: Vision Domain Adaptation Configuration
# Vision domain adaptation stage configuration file

# Data parameters
data_params:
  urpc_dataset_path: "data/urpc_dataset"  # URPC dataset path
  train_split: 0.8  # Training set ratio
  val_split: 0.2    # Validation set ratio
  batch_size: 32
  num_workers: 0  # Set to 0 to avoid multiprocessing issues on Windows
  pin_memory: false
  # Vision domain adaptation special parameters
  use_all_splits_for_training: false  # Use proper train/val split for supervised learning
  ignore_labels: false  # Use real labels for supervised classification training
  # URPC2020 specific parameters
  split_mapping:
    val: "valid"  # URPC uses valid instead of val
    validation: "valid"

# Model parameters
model_params:
  model_name: "vit_base_patch16_224"  # ViT model name
  pretrained: true                    # Use ImageNet pretrained weights
  num_classes: 4                      # URPC dataset classes (holothurian, echinus, scallop, starfish)
  freeze_layers: 8                    # Freeze first 8 Transformer blocks
  
# Training parameters
training_params:
  epochs: 50
  learning_rate: 0.0001
  weight_decay: 0.01
  optimizer: "adamw"
  warmup_epochs: 5
  
# Learning rate scheduler parameters
scheduler_params:
  type: "cosine"
  T_max: 50
  eta_min: 0.000001

# Data augmentation parameters
augmentation_params:
  # Underwater style data augmentation
  underwater_style: true
  resize: [224, 224]  # Ensure consistent image size
  color_jitter:
    brightness: 0.3
    contrast: 0.3
    saturation: 0.3
    hue: 0.1
  gaussian_blur:
    kernel_size: 3
    sigma: [0.1, 2.0]
  random_rotation: 15
  random_horizontal_flip: 0.5
  # Normalization parameters for ImageNet pretrained models
  normalize_mean: [0.485, 0.456, 0.406]
  normalize_std: [0.229, 0.224, 0.225]
  
  # Additional underwater-specific augmentations
  underwater_effects:
    blue_shift: true      # Simulate underwater light attenuation
    underwater_blur: true # Simulate light scattering
    contrast_reduction: true # Simulate visibility reduction
    brightness_adjustment: true # Simulate different depth lighting
    particle_noise: true  # Simulate suspended particles
  
# Checkpoint parameters
checkpoint_params:
  output_dir: "checkpoints/stage0_vision_finetune"
  save_freq: 10  # Save every 10 epochs
  save_best: true
  
# Logging parameters
logging_params:
  log_freq: 10  # Print log every 10 batches
  tensorboard_dir: "logs/stage0_vision_finetune"
  
# Evaluation parameters
evaluation_params:
  eval_freq: 5  # Evaluate every 5 epochs
  metrics: ["loss", "accuracy", "top5_accuracy"]
  save_predictions: true  # Save prediction results for analysis
  
# Device parameters
device_params:
  use_cuda: true
  mixed_precision: true  # Use mixed precision training
