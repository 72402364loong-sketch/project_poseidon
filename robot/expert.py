"""
ä¸“å®¶æ¥å£æ¨¡å—
æä¾›æ¨¡æ‹Ÿä¸“å®¶å’Œäººç±»ä¸“å®¶æ¥å£ï¼Œç”¨äºDAggerè®­ç»ƒä¸­çš„ä¸»åŠ¨å­¦ä¹ 
"""

import torch
import numpy as np
from typing import Dict, Any, List, Optional
import pygame
import logging


class SimulatedExpert:
    """
    æ¨¡æ‹Ÿä¸“å®¶ç±»
    ç”¨äºå¼€å‘å’Œè°ƒè¯•ï¼Œæä¾›åŸºäºè§„åˆ™çš„ç®€å•ä¸“å®¶ç­–ç•¥
    """
    
    def __init__(self, goal_position: List[float], action_scale: float = 0.1):
        """
        Args:
            goal_position: ç›®æ ‡ä½ç½® [x, y, z]
            action_scale: åŠ¨ä½œç¼©æ”¾å› å­
        """
        self.goal_position = np.array(goal_position)
        self.action_scale = action_scale
        self.logger = logging.getLogger(__name__)
        
        self.logger.info(f"æ¨¡æ‹Ÿä¸“å®¶å·²åˆå§‹åŒ–ï¼Œç›®æ ‡ä½ç½®: {self.goal_position}")
    
    def get_label(self, current_state: Dict[str, Any]) -> torch.Tensor:
        """
        è·å–ä¸“å®¶æ ‡æ³¨çš„åŠ¨ä½œ
        
        Args:
            current_state: å½“å‰çŠ¶æ€å­—å…¸ï¼ŒåŒ…å«ä½ç½®ä¿¡æ¯ç­‰
            
        Returns:
            ä¸“å®¶åŠ¨ä½œå¼ é‡ï¼Œå½¢çŠ¶ä¸º (7,) - [dx, dy, dz, d_roll, d_pitch, d_yaw, gripper_angle]
        """
        # ä»çŠ¶æ€ä¸­æå–å½“å‰ä½ç½®
        if 'position' in current_state:
            current_pos = np.array(current_state['position'])
        elif 'geometry_features' in current_state:
            # å¦‚æœçŠ¶æ€åŒ…å«å‡ ä½•ç‰¹å¾ï¼Œä½¿ç”¨å‰3ç»´ä½œä¸ºä½ç½®
            current_pos = np.array(current_state['geometry_features'][:3])
        else:
            # é»˜è®¤ä½ç½®
            current_pos = np.array([0.0, 0.0, 0.0])
        
        # è®¡ç®—æœå‘ç›®æ ‡çš„æ–¹å‘å‘é‡
        direction_to_goal = self.goal_position - current_pos
        
        # è®¡ç®—è·ç¦»
        distance = np.linalg.norm(direction_to_goal)
        
        # ç”Ÿæˆä¸“å®¶åŠ¨ä½œ
        expert_action = self._convert_direction_to_action(direction_to_goal, distance)
        
        self.logger.debug(f"[æ¨¡æ‹Ÿä¸“å®¶] å½“å‰ä½ç½®: {current_pos}, ç›®æ ‡ä½ç½®: {self.goal_position}")
        self.logger.debug(f"[æ¨¡æ‹Ÿä¸“å®¶] æ–¹å‘å‘é‡: {direction_to_goal}, è·ç¦»: {distance:.3f}")
        self.logger.debug(f"[æ¨¡æ‹Ÿä¸“å®¶] ä¸“å®¶åŠ¨ä½œ: {expert_action}")
        
        return expert_action
    
    def _convert_direction_to_action(self, direction: np.ndarray, distance: float) -> torch.Tensor:
        """
        å°†æ–¹å‘å‘é‡è½¬æ¢ä¸ºåŠ¨ä½œæŒ‡ä»¤
        
        Args:
            direction: æ–¹å‘å‘é‡
            distance: åˆ°ç›®æ ‡çš„è·ç¦»
            
        Returns:
            åŠ¨ä½œå¼ é‡
        """
        # å½’ä¸€åŒ–æ–¹å‘å‘é‡
        if distance > 1e-6:
            normalized_direction = direction / distance
        else:
            normalized_direction = np.zeros_like(direction)
        
        # æ ¹æ®è·ç¦»è°ƒæ•´åŠ¨ä½œå¹…åº¦
        if distance > 0.1:
            # è·ç¦»è¾ƒè¿œæ—¶ï¼Œä½¿ç”¨è¾ƒå¤§çš„åŠ¨ä½œå¹…åº¦
            action_magnitude = min(self.action_scale, distance * 0.5)
        else:
            # è·ç¦»è¾ƒè¿‘æ—¶ï¼Œä½¿ç”¨è¾ƒå°çš„åŠ¨ä½œå¹…åº¦
            action_magnitude = self.action_scale * 0.1
        
        # æ„å»º7ç»´åŠ¨ä½œå‘é‡
        action = np.zeros(7)
        
        # å‰6ç»´ï¼šæœºæ¢°è‡‚åŠ¨ä½œ [dx, dy, dz, d_roll, d_pitch, d_yaw]
        action[:3] = normalized_direction * action_magnitude  # ä½ç½®ç§»åŠ¨
        action[3:6] = np.random.normal(0, 0.01, 3)  # å°çš„éšæœºæ—‹è½¬
        
        # ç¬¬7ç»´ï¼šå¤¹çˆªåŠ¨ä½œ
        if distance < 0.05:
            # æ¥è¿‘ç›®æ ‡æ—¶ï¼Œå…³é—­å¤¹çˆª
            action[6] = 0.8  # å¤¹çˆªå…³é—­
        else:
            # è¿œç¦»ç›®æ ‡æ—¶ï¼Œä¿æŒå¤¹çˆªå¼€å¯
            action[6] = 0.2  # å¤¹çˆªå¼€å¯
        
        return torch.tensor(action, dtype=torch.float32)


class HumanExpert:
    """
    äººç±»ä¸“å®¶ç±»
    æä¾›çœŸå®çš„äººç±»ä¸“å®¶æ ‡æ³¨æ¥å£
    """
    
    def __init__(self, input_method: str = "keyboard"):
        """
        Args:
            input_method: è¾“å…¥æ–¹æ³• ("keyboard", "joystick")
        """
        self.input_method = input_method
        self.logger = logging.getLogger(__name__)
        
        if input_method == "joystick":
            self._init_joystick()
        else:
            self.logger.info("äººç±»ä¸“å®¶æ¥å£å·²åˆå§‹åŒ–ï¼ˆé”®ç›˜è¾“å…¥æ¨¡å¼ï¼‰")
    
    def _init_joystick(self):
        """åˆå§‹åŒ–æ¸¸æˆæ‰‹æŸ„"""
        try:
            pygame.init()
            pygame.joystick.init()
            
            if pygame.joystick.get_count() > 0:
                self.joystick = pygame.joystick.Joystick(0)
                self.joystick.init()
                self.logger.info(f"æ¸¸æˆæ‰‹æŸ„å·²è¿æ¥: {self.joystick.get_name()}")
            else:
                self.logger.warning("æœªæ£€æµ‹åˆ°æ¸¸æˆæ‰‹æŸ„ï¼Œå°†ä½¿ç”¨é”®ç›˜è¾“å…¥")
                self.input_method = "keyboard"
        except Exception as e:
            self.logger.error(f"æ¸¸æˆæ‰‹æŸ„åˆå§‹åŒ–å¤±è´¥: {e}")
            self.input_method = "keyboard"
    
    def get_label(self, current_state: Dict[str, Any]) -> torch.Tensor:
        """
        è·å–äººç±»ä¸“å®¶æ ‡æ³¨çš„åŠ¨ä½œ
        
        Args:
            current_state: å½“å‰çŠ¶æ€å­—å…¸
            
        Returns:
            ä¸“å®¶åŠ¨ä½œå¼ é‡ï¼Œå½¢çŠ¶ä¸º (7,)
        """
        print("=" * 60)
        print("ğŸ¤– æœºå™¨äººè¯·æ±‚ä¸“å®¶æ ‡æ³¨ï¼")
        print("=" * 60)
        
        # æ˜¾ç¤ºå½“å‰çŠ¶æ€ä¿¡æ¯
        self._display_current_state(current_state)
        
        if self.input_method == "joystick":
            action = self._get_joystick_input()
        else:
            action = self._get_keyboard_input()
        
        print(f"âœ… ä¸“å®¶åŠ¨ä½œ: {action.numpy()}")
        print("=" * 60)
        
        return action
    
    def _display_current_state(self, current_state: Dict[str, Any]):
        """æ˜¾ç¤ºå½“å‰çŠ¶æ€ä¿¡æ¯"""
        print("ğŸ“Š å½“å‰çŠ¶æ€:")
        
        if 'position' in current_state:
            pos = current_state['position']
            print(f"   ä½ç½®: [{pos[0]:.3f}, {pos[1]:.3f}, {pos[2]:.3f}]")
        
        if 'vision_features' in current_state:
            print(f"   è§†è§‰ç‰¹å¾ç»´åº¦: {len(current_state['vision_features'])}")
        
        if 'tactile_features' in current_state:
            print(f"   è§¦è§‰ç‰¹å¾ç»´åº¦: {len(current_state['tactile_features'])}")
        
        if 'classification_logits' in current_state:
            logits = current_state['classification_logits']
            predicted_class = torch.argmax(logits).item()
            confidence = torch.softmax(logits, dim=0)[predicted_class].item()
            print(f"   é¢„æµ‹ç±»åˆ«: {predicted_class}, ç½®ä¿¡åº¦: {confidence:.3f}")
        
        print()
    
    def _get_keyboard_input(self) -> torch.Tensor:
        """é€šè¿‡é”®ç›˜è·å–ä¸“å®¶è¾“å…¥"""
        print("âŒ¨ï¸  è¯·è¾“å…¥7ç»´åŠ¨ä½œå‘é‡:")
        print("   æ ¼å¼: dx,dy,dz,d_roll,d_pitch,d_yaw,gripper_angle")
        print("   ç¤ºä¾‹: 0.1,0.0,0.05,0.0,0.0,0.0,0.5")
        print("   è¯´æ˜: å‰6ç»´ä¸ºæœºæ¢°è‡‚åŠ¨ä½œï¼Œç¬¬7ç»´ä¸ºå¤¹çˆªè§’åº¦(0-1)")
        
        while True:
            try:
                action_str = input("   åŠ¨ä½œè¾“å…¥: ").strip()
                if not action_str:
                    print("   âŒ è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                # è§£æè¾“å…¥
                action_values = [float(x.strip()) for x in action_str.split(',')]
                
                if len(action_values) != 7:
                    print(f"   âŒ éœ€è¦7ä¸ªæ•°å€¼ï¼Œä½†è¾“å…¥äº†{len(action_values)}ä¸ªï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                # éªŒè¯å¤¹çˆªè§’åº¦èŒƒå›´
                if not (0.0 <= action_values[6] <= 1.0):
                    print("   âŒ å¤¹çˆªè§’åº¦å¿…é¡»åœ¨0-1ä¹‹é—´ï¼Œè¯·é‡æ–°è¾“å…¥")
                    continue
                
                return torch.tensor(action_values, dtype=torch.float32)
                
            except ValueError:
                print("   âŒ è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·è¾“å…¥7ä¸ªç”¨é€—å·åˆ†éš”çš„æ•°å€¼")
            except KeyboardInterrupt:
                print("\n   âš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œä½¿ç”¨é»˜è®¤åŠ¨ä½œ")
                return torch.zeros(7, dtype=torch.float32)
    
    def _get_joystick_input(self) -> torch.Tensor:
        """é€šè¿‡æ¸¸æˆæ‰‹æŸ„è·å–ä¸“å®¶è¾“å…¥"""
        print("ğŸ® æ¸¸æˆæ‰‹æŸ„è¾“å…¥æ¨¡å¼")
        print("   å·¦æ‘‡æ†: æ§åˆ¶x,yç§»åŠ¨")
        print("   å³æ‘‡æ†: æ§åˆ¶zç§»åŠ¨å’Œæ—‹è½¬")
        print("   æ‰³æœº: æ§åˆ¶å¤¹çˆª")
        print("   æŒ‰ä»»æ„æŒ‰é’®ç¡®è®¤åŠ¨ä½œ")
        
        action = torch.zeros(7, dtype=torch.float32)
        
        try:
            while True:
                pygame.event.pump()
                
                # è¯»å–æ‘‡æ†è¾“å…¥
                left_x = self.joystick.get_axis(0)  # å·¦æ‘‡æ†X
                left_y = self.joystick.get_axis(1)  # å·¦æ‘‡æ†Y
                right_x = self.joystick.get_axis(2)  # å³æ‘‡æ†X
                right_y = self.joystick.get_axis(3)  # å³æ‘‡æ†Y
                
                # è¯»å–æ‰³æœºè¾“å…¥
                left_trigger = (self.joystick.get_axis(4) + 1.0) / 2.0  # å·¦æ‰³æœº
                right_trigger = (self.joystick.get_axis(5) + 1.0) / 2.0  # å³æ‰³æœº
                
                # æ˜ å°„åˆ°åŠ¨ä½œ
                action[0] = left_x * 0.1  # dx
                action[1] = -left_y * 0.1  # dy (æ³¨æ„Yè½´æ–¹å‘)
                action[2] = right_y * 0.1  # dz
                action[3] = right_x * 0.05  # d_roll
                action[4] = 0.0  # d_pitch (æš‚æ—¶å›ºå®š)
                action[5] = 0.0  # d_yaw (æš‚æ—¶å›ºå®š)
                action[6] = right_trigger  # gripper_angle
                
                # æ˜¾ç¤ºå½“å‰åŠ¨ä½œ
                print(f"\r   å½“å‰åŠ¨ä½œ: [{action[0]:.3f}, {action[1]:.3f}, {action[2]:.3f}, "
                      f"{action[3]:.3f}, {action[4]:.3f}, {action[5]:.3f}, {action[6]:.3f}]", end="")
                
                # æ£€æŸ¥ç¡®è®¤æŒ‰é’®
                for i in range(self.joystick.get_numbuttons()):
                    if self.joystick.get_button(i):
                        print("\n   âœ… åŠ¨ä½œå·²ç¡®è®¤")
                        return action
                
                # æ£€æŸ¥é€€å‡ºæŒ‰é’®ï¼ˆé€šå¸¸æ˜¯"B"æŒ‰é’®ï¼‰
                if self.joystick.get_button(1):  # é€šå¸¸æ˜¯BæŒ‰é’®
                    print("\n   âš ï¸  ç”¨æˆ·å–æ¶ˆï¼Œä½¿ç”¨é»˜è®¤åŠ¨ä½œ")
                    return torch.zeros(7, dtype=torch.float32)
                
        except Exception as e:
            self.logger.error(f"æ¸¸æˆæ‰‹æŸ„è¾“å…¥é”™è¯¯: {e}")
            print(f"\n   âŒ æ¸¸æˆæ‰‹æŸ„è¾“å…¥é”™è¯¯: {e}")
            return torch.zeros(7, dtype=torch.float32)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'joystick'):
            pygame.quit()


class ExpertFactory:
    """
    ä¸“å®¶å·¥å‚ç±»
    æ ¹æ®é…ç½®åˆ›å»ºç›¸åº”çš„ä¸“å®¶å®ä¾‹
    """
    
    @staticmethod
    def create_expert(config: Dict[str, Any]) -> Any:
        """
        æ ¹æ®é…ç½®åˆ›å»ºä¸“å®¶å®ä¾‹
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«expert_interfaceç›¸å…³é…ç½®
            
        Returns:
            ä¸“å®¶å®ä¾‹
        """
        expert_config = config.get('expert_interface', {})
        use_simulated = expert_config.get('use_simulated_expert', True)
        
        if use_simulated:
            goal_position = expert_config.get('simulated_goal_position', [0.0, 0.0, 0.3])
            return SimulatedExpert(goal_position=goal_position)
        else:
            input_method = expert_config.get('input_method', 'keyboard')
            return HumanExpert(input_method=input_method)
